<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Ben Blog</title>
  
  <subtitle>一个无聊的博客。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://smallbenxiong.github.io/"/>
  <updated>2020-02-29T15:29:41.268Z</updated>
  <id>https://smallbenxiong.github.io/</id>
  
  <author>
    <name>Ben</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Flask | Centos部署Flask</title>
    <link href="https://smallbenxiong.github.io/2020/02/29/20200229-Centos%E9%83%A8%E7%BD%B2Flask/"/>
    <id>https://smallbenxiong.github.io/2020/02/29/20200229-Centos%E9%83%A8%E7%BD%B2Flask/</id>
    <published>2020-02-28T16:00:00.000Z</published>
    <updated>2020-02-29T15:29:41.268Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="Centos部署Flask"><a href="#Centos部署Flask" class="headerlink" title="Centos部署Flask"></a>Centos部署Flask</h1><p><strong>项目地址：<a href="http://47.101.180.197/" target="_blank" rel="noopener">水果识别demo，请使用Microsoft Edge！</a></strong></p><hr><h2 id="服务器代理"><a href="#服务器代理" class="headerlink" title="服务器代理"></a>服务器代理</h2><p>使用的代理一共有两个，nginx和uwsgi，先说明一下，如果不用nginx一样可以访问你的项目，使用nginx的目的是为了安全和负载均衡。配置了nginx做前端代理，uwsgi作后端代理的服务器(这里所说的前后端都是相对的位置，并无实际含义)，在处理来自Internet的请求时，要先经过nginx的处理，nginx把请求再交给uwsgi，经过uwsgi才能访问到项目本身。</p><p>没有nginx而只有uwsgi的服务器，则是Internet请求直接由uwsgi处理，并反馈到我们的项目中。<br>nginx可以实现安全过滤，防DDOS等保护安全的操作，并且如果配置了多台服务器，nginx可以保证服务器的负载相对均衡。</p><p>而uwsgi则是一个web服务器，实现了WSGI协议(Web Server Gateway Interface)，http协议等，它可以接收和处理请求，发出响应等。所以只用uwsgi也是可以的。</p><h2 id="CentOS环境配置"><a href="#CentOS环境配置" class="headerlink" title="CentOS环境配置"></a>CentOS环境配置</h2><h3 id="安装virtualenv"><a href="#安装virtualenv" class="headerlink" title="安装virtualenv"></a>安装virtualenv</h3><ol><li>安装virtualenv<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install virtualenv</span><br></pre></td></tr></table></figure></li><li>创建虚拟环境（环境名为python3.6）<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># virtualenv  -p &#x2F;usr&#x2F;local&#x2F;python3&#x2F;bin&#x2F;python3.6 &#x2F;python3.6</span><br></pre></td></tr></table></figure></li><li>进入虚拟环境（每次编辑需进入此虚拟环境）<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># source &#x2F;python3.6&#x2F;bin&#x2F;activate</span><br></pre></td></tr></table></figure></li><li>成功进入虚拟环境显示<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(python3.6) [root@···]#</span><br></pre></td></tr></table></figure></li></ol><h3 id="安装所需源"><a href="#安装所需源" class="headerlink" title="安装所需源"></a>安装所需源</h3><ol><li>在虚拟环境中安装flask和uwsgi<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># pip install flask</span><br><span class="line"># pip install uwsgi</span><br></pre></td></tr></table></figure></li><li>在虚拟环境中安装flask项目所需源<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># pip3 install pillow</span><br><span class="line"># pip3 install opencv-python</span><br><span class="line"># pip3 install tensorflow&#x3D;&#x3D;1.5</span><br><span class="line"># pip3 install numpy</span><br><span class="line"># pip3 install requests</span><br></pre></td></tr></table></figure></li></ol><h3 id="安装Nginx"><a href="#安装Nginx" class="headerlink" title="安装Nginx"></a>安装Nginx</h3><ol><li>下载<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 下载版本号可根据目前官网最新稳定版自行调整</span><br><span class="line">wget -c https:&#x2F;&#x2F;nginx.org&#x2F;download&#x2F;nginx-1.16.1.tar.gz</span><br></pre></td></tr></table></figure></li><li>安装<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 根目录使用ls命令可以看到下载的nginx压缩包，然后解压</span><br><span class="line">tar -zxvf nginx-1.16.1.tar.gz</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 解压后进入目录</span><br><span class="line">cd nginx-1.16.1</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 使用默认配置</span><br><span class="line">.&#x2F;configure</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 编译安装</span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure></li><li>启动<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># cd &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin</span><br><span class="line">.&#x2F;nginx     #启动</span><br><span class="line">.&#x2F;nginx -s stop  #停止，直接查找nginx进程id再使用kill命令强制杀掉进程</span><br><span class="line">.&#x2F;nginx -s quit  #退出停止，等待nginx进程处理完任务再进行停止</span><br><span class="line">.&#x2F;nginx -s reload  #重新加载配置文件，修改nginx.conf后使用该命令，新配置即可生效</span><br><span class="line"></span><br><span class="line">查看nginx进程</span><br><span class="line"># ps aux|grep nginx</span><br><span class="line"></span><br><span class="line">停止nginx</span><br><span class="line"># service nginx stop</span><br><span class="line"></span><br><span class="line">关闭nginx的进程</span><br><span class="line">killall -9 nginx</span><br></pre></td></tr></table></figure></li></ol><p>参考：<br><a href="https://www.cnblogs.com/huiyi0521/p/10253341.html" target="_blank" rel="noopener">CentOS7 nginx安装与卸载</a><br><a href="https://my.oschina.net/yueshengwujie/blog/3099219" target="_blank" rel="noopener">centos7安装Nginx、使用nginx记录</a></p><h3 id="kill杀进程"><a href="#kill杀进程" class="headerlink" title="kill杀进程"></a>kill杀进程</h3><ol><li>用kill来杀死某一个进程<br> kill，加选项-9，加PID，表示杀死进程编号为PID的这个进程<br> -1 重启<br> #kill -9 PID</li><li>用killall杀死一类进程<br> #killall，加选项-9，加服务名， 表示杀死该服务的所有进程<br> -1 重启<br> #killall -9 service</li><li>用pkill踢出某个终端<br> pkill，加选项-9，加终端号，表示踢出该终端<br> -1 重启<br> #pkill -9 pts/0</li><li>查看进程</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#ps -aux | grep gunicorn</span><br></pre></td></tr></table></figure><p>参考：<a href="https://www.cnblogs.com/kinwing/p/11104966.html" target="_blank" rel="noopener">centos下kill、killall、pkill命令区别</a>   </p><h2 id="Flask配置"><a href="#Flask配置" class="headerlink" title="Flask配置"></a>Flask配置</h2><h3 id="配置uwsgi"><a href="#配置uwsgi" class="headerlink" title="配置uwsgi"></a>配置uwsgi</h3><p>文件路径：/usr/local/nginx/html/fruit_classification/uwsgiconfig.ini<br>在部署项目的根目录下创建配置文件uwsgiconfig.ini，添加配置内容如下：  </p><pre><code>[uwsgi]  # uwsgi 启动时所使用的地址与端口（可以与项目端口不一致）  socket = 127.0.0.1:8001  # 指向网站目录  chdir = /usr/local/nginx/html/fruit_classification/  # python 启动程序文件  wsgi-file = /usr/local/nginx/html/fruit_classification/  app.py  # python 程序内用以启动的 application 变量名  callable = app  # 处理器数  processes = 4  # 线程数  threads = 2  # 缓冲区  buffer-size = 32768  # 状态检测地址  stats = 127.0.0.1:9191  # 日志保存  daemonize = /usr/local/nginx/html/fruit_classification/  fruit_classification.log   </code></pre><h3 id="配置nginx"><a href="#配置nginx" class="headerlink" title="配置nginx"></a>配置nginx</h3><p>文件路径：/usr/local/nginx/conf/nginx.conf</p><pre><code>server {          listen       80;            server_name  47.101.180.197;            #charset koi8-r;          #access_log  logs/host.access.log  main;          location / {              include uwsgi_params;              uwsgi_pass 127.0.0.1:8001;              uwsgi_param UWSGI_PYHOME /usr/local/python3/  bin/python3.6;  #python位置，要么是虚拟机，要么是运行的环境变量位置              uwsgi_param UWSGI_CHDIR /usr/local/nginx/html/fruit_classification;  #项目根目录              uwsgi_param UWSGI_SCRIPT manage:app;              # root   html;              # index  index.html index.htm;            }  </code></pre><h2 id="启动Flask"><a href="#启动Flask" class="headerlink" title="启动Flask"></a>启动Flask</h2><h3 id="上传项目（WinSCP）"><a href="#上传项目（WinSCP）" class="headerlink" title="上传项目（WinSCP）"></a>上传项目（WinSCP）</h3><p>项目上传地址：/usr/local/nginx/html/fruit_classification</p><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># source &#x2F;python3.6&#x2F;bin&#x2F;activate</span><br><span class="line"># cd &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin</span><br><span class="line"># .&#x2F;nginx</span><br><span class="line"># uwsgi --ini &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;html&#x2F;fruit_classification&#x2F;uwsgiconfig.ini</span><br></pre></td></tr></table></figure><p>参考：<br><a href="https://www.ucloud.cn/yun/45620.html" target="_blank" rel="noopener">CentOS 下用 Nginx 和 uwsgi 部署 flask 项目</a><br><a href="https://www.cnblogs.com/Sugar-Chl/p/9497901.html" target="_blank" rel="noopener">阿里云服务器Centos上部署一个Flask项目</a><br><a href="https://www.cnblogs.com/nmsghgnv/p/11431729.html" target="_blank" rel="noopener">centos服务器部署flask项目</a><br><a href="https://my.oschina.net/yueshengwujie/blog/3099219" target="_blank" rel="noopener">centos7安装Nginx、使用nginx记录</a><br><a href="https://www.cnblogs.com/huiyi0521/p/10253341.html" target="_blank" rel="noopener">CentOS7 nginx安装与卸载</a></p><hr><p><strong>项目地址：<a href="http://47.101.180.197/" target="_blank" rel="noopener">水果识别demo，请使用Microsoft Edge！</a></strong></p>]]></content>
    
    <summary type="html">
    
      Centos部署Flask
    
    </summary>
    
    
      <category term="Flask" scheme="https://smallbenxiong.github.io/categories/Flask/"/>
    
    
      <category term="Flask" scheme="https://smallbenxiong.github.io/tags/Flask/"/>
    
      <category term="Centos" scheme="https://smallbenxiong.github.io/tags/Centos/"/>
    
      <category term="阿里云" scheme="https://smallbenxiong.github.io/tags/%E9%98%BF%E9%87%8C%E4%BA%91/"/>
    
      <category term="水果识别" scheme="https://smallbenxiong.github.io/tags/%E6%B0%B4%E6%9E%9C%E8%AF%86%E5%88%AB/"/>
    
  </entry>
  
  <entry>
    <title>数学 | 机器学习中的线性代数</title>
    <link href="https://smallbenxiong.github.io/2020/01/08/20200108-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    <id>https://smallbenxiong.github.io/2020/01/08/20200108-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/</id>
    <published>2020-01-07T16:00:00.000Z</published>
    <updated>2020-01-08T16:38:19.712Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="机器学习中的线性代数"><a href="#机器学习中的线性代数" class="headerlink" title="机器学习中的线性代数"></a>机器学习中的线性代数</h1><h2 id="线性代数的数学对象"><a href="#线性代数的数学对象" class="headerlink" title="线性代数的数学对象"></a>线性代数的数学对象</h2><ol><li>标量：标量只是一个单一的数字  </li><li>向量：向量是一个有序的数学数组，可以在一行或一列中</li><li>矩阵: 矩阵是一个有序的二维数组，它有两个索引。一个指向该行，一个指向该列</li></ol><p><img alt="数学对象" data-src="/2020/01/08/20200108-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E6%95%B0%E5%AD%A6%E5%AF%B9%E8%B1%A1.png" class="lazyload"></p><h2 id="线性代数基本计算规则"><a href="#线性代数基本计算规则" class="headerlink" title="线性代数基本计算规则"></a>线性代数基本计算规则</h2><h3 id="矩阵标量运算"><a href="#矩阵标量运算" class="headerlink" title="矩阵标量运算"></a>矩阵标量运算</h3><p>如果一个矩阵加减乘除一个标量，那么这个矩阵的每一个元素进行数学运算<br><img alt="矩阵标量运算" data-src="/2020/01/08/20200108-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E7%9F%A9%E9%98%B5%E6%A0%87%E9%87%8F%E8%BF%90%E7%AE%97.png" class="lazyload"></p><h3 id="矩阵-矩阵加法和减法"><a href="#矩阵-矩阵加法和减法" class="headerlink" title="矩阵-矩阵加法和减法"></a>矩阵-矩阵加法和减法</h3><p>矩阵-矩阵加法或者减法要求矩阵具有相同的尺寸，并且结果将是具有相同尺寸的矩阵。只需在第一个矩阵中添加或减去第二个矩阵的每个值及其对应的值<br><img alt="矩阵-矩阵加法和减法" data-src="/2020/01/08/20200108-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E7%9F%A9%E9%98%B5-%E7%9F%A9%E9%98%B5%E5%8A%A0%E6%B3%95%E5%92%8C%E5%87%8F%E6%B3%95.png" class="lazyload"></p><h3 id="矩阵-矩阵点乘-点积"><a href="#矩阵-矩阵点乘-点积" class="headerlink" title="矩阵-矩阵点乘(点积)"></a>矩阵-矩阵点乘(点积)</h3><p>矩阵-矩阵点乘要求是矩阵具有相同的尺寸，矩阵各个对应元素相乘<br><img alt="矩阵-矩阵点乘(点积)" data-src="/2020/01/08/20200108-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E7%9F%A9%E9%98%B5-%E7%9F%A9%E9%98%B5%E7%82%B9%E4%B9%98(%E7%82%B9%E7%A7%AF).png" class="lazyload"></p><h3 id="矩阵-矩阵相乘-叉乘"><a href="#矩阵-矩阵相乘-叉乘" class="headerlink" title="矩阵-矩阵相乘(叉乘)"></a>矩阵-矩阵相乘(叉乘)</h3><p>如果第一个矩阵列的数量和第二个矩阵行数要相等，才能将矩阵相乘。结果矩阵具有与第一个矩阵相同的行数和第二个矩阵相同的列数<br><img alt="矩阵-矩阵相乘(叉乘)" data-src="/2020/01/08/20200108-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E7%9F%A9%E9%98%B5-%E7%9F%A9%E9%98%B5%E7%9B%B8%E4%B9%98(%E5%8F%89%E4%B9%98).png" class="lazyload"></p><h3 id="矩阵-向量乘法"><a href="#矩阵-向量乘法" class="headerlink" title="矩阵-向量乘法"></a>矩阵-向量乘法</h3><p>看作矩阵-矩阵叉乘的特例<br><img alt="矩阵-向量乘法" data-src="/2020/01/08/20200108-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E7%9F%A9%E9%98%B5-%E5%90%91%E9%87%8F%E4%B9%98%E6%B3%95.png" class="lazyload"></p><h3 id="向量-向量乘法-列向量-行向量"><a href="#向量-向量乘法-列向量-行向量" class="headerlink" title="向量-向量乘法(列向量-行向量)"></a>向量-向量乘法(列向量-行向量)</h3><p>看着矩阵-矩阵叉乘的特例<br><img alt="向量-向量乘法(列向量-行向量)" data-src="/2020/01/08/20200108-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E5%90%91%E9%87%8F-%E5%90%91%E9%87%8F%E4%B9%98%E6%B3%95(%E5%88%97%E5%90%91%E9%87%8F-%E8%A1%8C%E5%90%91%E9%87%8F).png" class="lazyload"></p><h3 id="向量-向量乘法-行向量-列向量"><a href="#向量-向量乘法-行向量-列向量" class="headerlink" title="向量-向量乘法(行向量-列向量)"></a>向量-向量乘法(行向量-列向量)</h3><p>看着矩阵-矩阵叉乘的特例<br><img alt="向量-向量乘法(行向量-列向量)" data-src="/2020/01/08/20200108-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E5%90%91%E9%87%8F-%E5%90%91%E9%87%8F%E4%B9%98%E6%B3%95(%E8%A1%8C%E5%90%91%E9%87%8F-%E5%88%97%E5%90%91%E9%87%8F).png" class="lazyload"></p><h3 id="矩阵转置"><a href="#矩阵转置" class="headerlink" title="矩阵转置"></a>矩阵转置</h3><p>第一列变成转置矩阵的第一行，第二列变成了矩阵转置的第二行，一个m<em>n的矩阵被转换成为一个n</em>m 的矩阵。<br><img alt="矩阵转置" data-src="/2020/01/08/20200108-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E7%9F%A9%E9%98%B5%E8%BD%AC%E7%BD%AE.png" class="lazyload"></p>]]></content>
    
    <summary type="html">
    
      机器学习中的线性代数
    
    </summary>
    
    
      <category term="数学" scheme="https://smallbenxiong.github.io/categories/%E6%95%B0%E5%AD%A6/"/>
    
    
      <category term="数学" scheme="https://smallbenxiong.github.io/tags/%E6%95%B0%E5%AD%A6/"/>
    
      <category term="线性代数" scheme="https://smallbenxiong.github.io/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    
      <category term="机器学习" scheme="https://smallbenxiong.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow | TensorFlow实现单变量线性回归</title>
    <link href="https://smallbenxiong.github.io/2020/01/06/20200106-TensorFlow%E5%AE%9E%E7%8E%B0%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    <id>https://smallbenxiong.github.io/2020/01/06/20200106-TensorFlow%E5%AE%9E%E7%8E%B0%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</id>
    <published>2020-01-05T16:00:00.000Z</published>
    <updated>2020-01-06T14:25:11.168Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="TensorFlow实现单变量线性回归"><a href="#TensorFlow实现单变量线性回归" class="headerlink" title="TensorFlow实现单变量线性回归"></a>TensorFlow实现单变量线性回归</h1><p><strong>学习的函数为线性函数 y=2x+1</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在Jupyter中显示图像需使用matplotlib的inline模式</span></span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><h2 id="生成人工数据集"><a href="#生成人工数据集" class="headerlink" title="生成人工数据集"></a>生成人工数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置随机种子</span></span><br><span class="line">np.random.seed(<span class="number">5</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 直接采用np生成等差数列的方法，生成100个点，每个点的取值在-1~1之间</span></span><br><span class="line">x_data = np.linspace(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># y = 2x + 1 + 噪声,其中噪声的维度与x_data一致。随机振幅，幅度设为0.4</span></span><br><span class="line">y_data = <span class="number">2</span> * x_data + <span class="number">1.0</span> + np.random.randn(*x_data.shape) * <span class="number">0.4</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># numpy.randoom.randn(d0,d1,…,dn)是从标准正态分布中返回一个或多个样本值</span></span><br><span class="line"><span class="comment"># 标准正态分布又称u分布，是以0为均值，1为标准差的正态分布，记为N(0, 1)</span></span><br><span class="line"></span><br><span class="line">np.random.randn(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><pre><code>array([ 0.79242262,  0.17076445, -1.75374086,  0.63029648,  0.49832921,        1.01813761, -0.84646862,  2.52080763, -1.23238611,  0.72695326])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># x_data.shape值为一个元组</span></span><br><span class="line">x_data.shape</span><br></pre></td></tr></table></figure><pre><code>(100,)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实参前面加上*或者**时，意味着拆包。单个*表示将元组拆成一个个单独的实参</span></span><br><span class="line"><span class="comment"># np.random.randn(*x_data.shape)和np.random.randn(100)一样</span></span><br><span class="line"></span><br><span class="line">np.random.randn(*x_data.shape)</span><br></pre></td></tr></table></figure><pre><code>array([ 0.04595522, -0.48713265,  0.81613236, -0.28143012, -2.33562182,       -1.16727845,  0.45765807,  2.23796561, -1.4812592 , -0.01694532,        1.45073354,  0.60687032, -0.37562084, -1.42192455, -1.7811513 ,       -0.74790579, -0.36840953, -2.24911813, -1.69367504,  0.30364847,       -0.40899234, -0.75483059, -0.40751917, -0.81262476,  0.92751621,        1.63995407,  2.07361553,  0.70979786,  0.74715259,  1.46309548,        1.73844881,  1.46520488,  1.21228341, -0.6346525 , -1.5996985 ,        0.87715281, -0.09383245, -0.05567103, -0.88942073, -1.30095145,        1.40216662,  0.46510099, -1.06503262,  0.39042061,  0.30560017,        0.52184949,  2.23327081, -0.0347021 , -1.27962318,  0.03654264,       -0.64635659,  0.54856784,  0.21054246,  0.34650175, -0.56705117,        0.41367881, -0.51025606,  0.51725935, -0.30100513, -1.11840643,        0.49852362, -0.70609387,  1.4438811 ,  0.44295626,  0.46770521,        0.10134479, -0.05935198, -2.38669774,  1.22217056, -0.81391201,        0.95626186, -0.63851056, -0.14312642, -0.22418983, -1.03849524,       -0.17170905,  0.47634618, -0.41417827, -1.26408334, -0.57321556,        0.24981732,  1.14720208,  0.83594396,  0.28740365, -0.9955963 ,        0.90688947,  0.02421074, -0.23998173,  0.91011056,  0.61784475,        0.49961804, -1.15154425, -0.6105164 , -1.70388541,  0.19443738,        0.02824125,  0.93256051,  0.21204332, -0.36794457,  2.1114884 ])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.random.randn(<span class="number">100</span>)</span><br></pre></td></tr></table></figure><pre><code>array([-1.02957349, -1.33628031, -0.61056736,  0.52469426, -0.34930813,       -0.44073846, -1.1212876 ,  1.47284473, -0.62337224, -1.08070195,       -0.12253009, -0.8077431 , -0.23255622,  1.33515034, -0.44645673,       -0.04978868, -0.36854478, -0.19173957,  0.81967992,  0.53163372,       -0.34161504, -0.93090048, -0.13421699,  0.83259361, -0.01735327,       -0.12765822, -1.80791662,  0.99396898, -1.49112886, -1.28210748,       -0.37570741,  0.03464388,  0.04507816, -0.76374689, -0.31313851,       -0.60698954, -1.80955123, -0.25551774, -0.69379935,  0.41919776,       -0.14520019,  0.9638013 ,  0.69622199,  0.89940546,  1.20837807,        0.6932537 , -0.16636061,  1.35311311, -0.92862651, -0.03547249,        0.85964595, -0.28749661,  0.71494995, -0.8034526 , -0.54048196,        0.54617743,  0.71188926,  1.19715449, -0.07006703,  0.29822712,        0.62619261,  0.46743206, -1.30262143, -0.57008965,  1.44295001,       -1.24399513,  0.62888033, -0.42559213,  1.00320956, -0.77817761,        0.04894463, -2.02640189, -0.04193635,  1.07454278, -1.5008594 ,        1.18574443, -0.71508124, -0.05123853, -2.77458336,  1.07862813,       -0.87568592, -0.53810932, -1.2782157 , -0.99276945,  1.14342789,       -0.5090726 ,  0.89500094, -0.17620337,  0.34608347, -0.50631013,        0.42716402,  2.58856959,  0.65289301,  0.50583979, -0.47595083,        1.01090874,  1.35920097, -1.70208997, -1.38033223,  2.10177668])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># y = 2x+1+噪声</span></span><br><span class="line">y_data = <span class="number">2</span> * x_data + <span class="number">1.0</span> + np.random.randn(<span class="number">100</span>) * <span class="number">0.4</span></span><br></pre></td></tr></table></figure><h3 id="matplotlib画出生成结果"><a href="#matplotlib画出生成结果" class="headerlink" title="matplotlib画出生成结果"></a>matplotlib画出生成结果</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 画出随机生成数据散点图</span></span><br><span class="line">plt.scatter(x_data, y_data)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.collections.PathCollection at 0x22c32a84c18&gt;</code></pre><p><img alt="png" data-src="/2020/01/06/20200106-TensorFlow%E5%AE%9E%E7%8E%B0%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/output_11_1.png" class="lazyload"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 画出想要学习到的线性函数y = 2x + 1</span></span><br><span class="line">plt.scatter(x_data, y_data)</span><br><span class="line">plt.plot(x_data, <span class="number">1.0</span> + <span class="number">2</span> * x_data, color = <span class="string">'red'</span>, linewidth=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x22c32b14f28&gt;]</code></pre><p><img alt="png" data-src="/2020/01/06/20200106-TensorFlow%E5%AE%9E%E7%8E%B0%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/output_12_1.png" class="lazyload"></p><h2 id="构建模型"><a href="#构建模型" class="headerlink" title="构建模型"></a>构建模型</h2><h3 id="定义x和y的占位符"><a href="#定义x和y的占位符" class="headerlink" title="定义x和y的占位符"></a>定义x和y的占位符</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义训练数据的占位符，x是特征值，y是标签纸</span></span><br><span class="line">x = tf.placeholder(<span class="string">"float"</span>, name = <span class="string">"x"</span>)</span><br><span class="line">y = tf.placeholder(<span class="string">"float"</span>, name = <span class="string">"y"</span>)</span><br></pre></td></tr></table></figure><h3 id="构建回归模型"><a href="#构建回归模型" class="headerlink" title="构建回归模型"></a>构建回归模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义模型函数</span></span><br><span class="line"><span class="comment"># 通过训练模型求出最合适的w，b，使总的损失最小</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(x, w, b)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.multiply(x, w) + b <span class="comment"># w*x+b</span></span><br></pre></td></tr></table></figure><h3 id="创建变量"><a href="#创建变量" class="headerlink" title="创建变量"></a>创建变量</h3><ul><li>变量声明函数使tf.Variable</li><li>变量作用是保存和更新模型参数   </li><li>变量的初始化可以是随机数、常数，或者其他变量的初始值计算得到</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建变量</span></span><br><span class="line"><span class="comment"># 构建线性函数的斜率，变量w</span></span><br><span class="line">w = tf.Variable(<span class="number">1.0</span>, name = <span class="string">"w0"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#构建线性函数的截距，变量b</span></span><br><span class="line">b = tf.Variable(<span class="number">0.0</span>, name = <span class="string">"b0"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pred是预测值，前向计算</span></span><br><span class="line">pred = model(x, w, b) <span class="comment">#即wx+b的计算值</span></span><br></pre></td></tr></table></figure><h2 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h2><h3 id="设置训练参数"><a href="#设置训练参数" class="headerlink" title="设置训练参数"></a>设置训练参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 迭代次数（训练轮数）</span></span><br><span class="line">train_epochs = <span class="number">10</span></span><br></pre></td></tr></table></figure><p>关于学习率（learning_rate）的设置</p><ul><li>学习率作用：控制参数更新的幅度</li><li>学习率设置过大：可能导致参数在极值附件来回摇摆，无法保证收敛</li><li>学习率设置国小：虽然能保证收敛，但是优化速度大大降低，需要迭代次数更多次数才能达到比较理想的优化效果</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 学习率</span></span><br><span class="line">learning_rate = <span class="number">0.05</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 控制显示loss值的粒度</span></span><br><span class="line">display_step = <span class="number">10</span></span><br></pre></td></tr></table></figure><h3 id="定义损失函数"><a href="#定义损失函数" class="headerlink" title="定义损失函数"></a>定义损失函数</h3><ul><li>损失函数用于描述预测值和真实值之间的误差，从而指导模型收敛方向</li><li>常见损失函数：均方差（Mean Square Errir,MSE）和交叉熵（cross-entropy）</li></ul><p>$ L_2 损失函数 $</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 采用均方差作为损失函数</span></span><br><span class="line"></span><br><span class="line">loss_function = tf.reduce_mean(tf.square(y-pred)) <span class="comment"># reduce_mean平均值，square平方</span></span><br></pre></td></tr></table></figure><h3 id="定义优化器"><a href="#定义优化器" class="headerlink" title="定义优化器"></a>定义优化器</h3><ul><li>定义优化器Optimizer，初始化一个GradientDescentOptimizer</li><li>设置学习率和优化目标：最小化损失</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 梯度下降优化器</span></span><br><span class="line"><span class="comment"># GradientDescentOptimizer(learning_rate)学习率learning_rate来指导优化</span></span><br><span class="line"><span class="comment"># minimize(loss_function)把损失函数loss_function最小化</span></span><br><span class="line"></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss_function)</span><br></pre></td></tr></table></figure><h3 id="创建会话"><a href="#创建会话" class="headerlink" title="创建会话"></a>创建会话</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 声明会话</span></span><br><span class="line">sess = tf.Session()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 变量初始化</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"><span class="comment"># init是一个节点，需要run</span></span><br><span class="line">sess.run(init)</span><br></pre></td></tr></table></figure><h3 id="迭代训练"><a href="#迭代训练" class="headerlink" title="迭代训练"></a>迭代训练</h3><p>模型训练阶段设置迭代轮次，每次通过将样本逐个输入模型，进行梯度下降优化操作，每轮迭代后绘制出模型曲线</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 显示损失值的训练</span></span><br><span class="line"><span class="comment"># 开始训练，轮次为epoch，采用SGD随机梯度下降优化方法</span></span><br><span class="line">step = <span class="number">0</span>   <span class="comment"># 记录训练步数</span></span><br><span class="line">loss_list = []  <span class="comment"># 用于保存loss值的列表</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(train_epochs):</span><br><span class="line">    <span class="keyword">for</span> xs, ys <span class="keyword">in</span> zip(x_data, y_data):</span><br><span class="line">        <span class="comment"># 模型优化，运行两个节点优化器和损失函数</span></span><br><span class="line">        <span class="comment"># 给占位符x和y填充真实值xs和ys</span></span><br><span class="line">        _, loss = sess.run([optimizer, loss_function], feed_dict=&#123;x:xs, y:ys&#125;)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 显示损失值loss</span></span><br><span class="line">        <span class="comment"># display_step：控制报告的粒度</span></span><br><span class="line">        <span class="comment"># 例如，如果display_step设为2，则将每训练2个样本输出一次损失值</span></span><br><span class="line">        <span class="comment"># 与超参数不同，修改display_step 不会更改模型所学习的规律</span></span><br><span class="line">        loss_list.append(loss)</span><br><span class="line">        step = step+<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> step % display_step == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"Train Epoch:"</span>,<span class="string">'%02d'</span> % (epoch+<span class="number">1</span>), <span class="string">"Step:%03d"</span> % (step),<span class="string">"loss="</span>,<span class="string">"&#123;:.9f&#125;"</span>.format(loss))</span><br><span class="line">        </span><br><span class="line">    b0temp = b.eval(session=sess)</span><br><span class="line">    w0temp = w.eval(session=sess)</span><br><span class="line">    plt.plot (x_data, w0temp * x_data + b0temp) <span class="comment">#画图</span></span><br></pre></td></tr></table></figure><pre><code>Train Epoch: 01 Step:010 loss= 0.053888980Train Epoch: 01 Step:020 loss= 0.000218245Train Epoch: 01 Step:030 loss= 0.019443041Train Epoch: 01 Step:040 loss= 0.589532554Train Epoch: 01 Step:050 loss= 0.000989183Train Epoch: 01 Step:060 loss= 0.142488658Train Epoch: 01 Step:070 loss= 0.046271212Train Epoch: 01 Step:080 loss= 0.008660123Train Epoch: 01 Step:090 loss= 0.241159379Train Epoch: 01 Step:100 loss= 0.000514947Train Epoch: 02 Step:110 loss= 0.317517459Train Epoch: 02 Step:120 loss= 0.032397330Train Epoch: 02 Step:130 loss= 0.093368128Train Epoch: 02 Step:140 loss= 0.332103789Train Epoch: 02 Step:150 loss= 0.060521714Train Epoch: 02 Step:160 loss= 0.024084859Train Epoch: 02 Step:170 loss= 0.178793266Train Epoch: 02 Step:180 loss= 0.006461896Train Epoch: 02 Step:190 loss= 0.129687995Train Epoch: 02 Step:200 loss= 0.013333416Train Epoch: 03 Step:210 loss= 0.129900724Train Epoch: 03 Step:220 loss= 0.023582600Train Epoch: 03 Step:230 loss= 0.096030191Train Epoch: 03 Step:240 loss= 0.317024857Train Epoch: 03 Step:250 loss= 0.069221057Train Epoch: 03 Step:260 loss= 0.018716505Train Epoch: 03 Step:270 loss= 0.193809599Train Epoch: 03 Step:280 loss= 0.009021518Train Epoch: 03 Step:290 loss= 0.121858403Train Epoch: 03 Step:300 loss= 0.015201909Train Epoch: 04 Step:310 loss= 0.117845014Train Epoch: 04 Step:320 loss= 0.022902815Train Epoch: 04 Step:330 loss= 0.096256405Train Epoch: 04 Step:340 loss= 0.315768689Train Epoch: 04 Step:350 loss= 0.069981642Train Epoch: 04 Step:360 loss= 0.018294554Train Epoch: 04 Step:370 loss= 0.195104137Train Epoch: 04 Step:380 loss= 0.009256961Train Epoch: 04 Step:390 loss= 0.121209100Train Epoch: 04 Step:400 loss= 0.015365199Train Epoch: 05 Step:410 loss= 0.116854727Train Epoch: 05 Step:420 loss= 0.022845931Train Epoch: 05 Step:430 loss= 0.096275523Train Epoch: 05 Step:440 loss= 0.315662980Train Epoch: 05 Step:450 loss= 0.070045985Train Epoch: 05 Step:460 loss= 0.018259227Train Epoch: 05 Step:470 loss= 0.195213363Train Epoch: 05 Step:480 loss= 0.009276883Train Epoch: 05 Step:490 loss= 0.121154651Train Epoch: 05 Step:500 loss= 0.015378974Train Epoch: 06 Step:510 loss= 0.116771445Train Epoch: 06 Step:520 loss= 0.022841139Train Epoch: 06 Step:530 loss= 0.096277155Train Epoch: 06 Step:540 loss= 0.315654010Train Epoch: 06 Step:550 loss= 0.070051350Train Epoch: 06 Step:560 loss= 0.018256264Train Epoch: 06 Step:570 loss= 0.195222735Train Epoch: 06 Step:580 loss= 0.009278628Train Epoch: 06 Step:590 loss= 0.121149838Train Epoch: 06 Step:600 loss= 0.015380217Train Epoch: 07 Step:610 loss= 0.116764441Train Epoch: 07 Step:620 loss= 0.022840742Train Epoch: 07 Step:630 loss= 0.096277267Train Epoch: 07 Step:640 loss= 0.315653324Train Epoch: 07 Step:650 loss= 0.070051797Train Epoch: 07 Step:660 loss= 0.018256038Train Epoch: 07 Step:670 loss= 0.195223376Train Epoch: 07 Step:680 loss= 0.009278720Train Epoch: 07 Step:690 loss= 0.121149674Train Epoch: 07 Step:700 loss= 0.015380275Train Epoch: 08 Step:710 loss= 0.116763875Train Epoch: 08 Step:720 loss= 0.022840688Train Epoch: 08 Step:730 loss= 0.096277334Train Epoch: 08 Step:740 loss= 0.315653145Train Epoch: 08 Step:750 loss= 0.070051856Train Epoch: 08 Step:760 loss= 0.018255942Train Epoch: 08 Step:770 loss= 0.195223376Train Epoch: 08 Step:780 loss= 0.009278720Train Epoch: 08 Step:790 loss= 0.121149503Train Epoch: 08 Step:800 loss= 0.015380275Train Epoch: 09 Step:810 loss= 0.116763793Train Epoch: 09 Step:820 loss= 0.022840688Train Epoch: 09 Step:830 loss= 0.096277334Train Epoch: 09 Step:840 loss= 0.315653145Train Epoch: 09 Step:850 loss= 0.070051923Train Epoch: 09 Step:860 loss= 0.018255910Train Epoch: 09 Step:870 loss= 0.195223585Train Epoch: 09 Step:880 loss= 0.009278766Train Epoch: 09 Step:890 loss= 0.121149339Train Epoch: 09 Step:900 loss= 0.015380275Train Epoch: 10 Step:910 loss= 0.116763711Train Epoch: 10 Step:920 loss= 0.022840671Train Epoch: 10 Step:930 loss= 0.096277304Train Epoch: 10 Step:940 loss= 0.315653145Train Epoch: 10 Step:950 loss= 0.070051856Train Epoch: 10 Step:960 loss= 0.018255973Train Epoch: 10 Step:970 loss= 0.195223376Train Epoch: 10 Step:980 loss= 0.009278720Train Epoch: 10 Step:990 loss= 0.121149503Train Epoch: 10 Step:1000 loss= 0.015380275</code></pre><p><img alt="png" data-src="/2020/01/06/20200106-TensorFlow%E5%AE%9E%E7%8E%B0%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/output_40_1.png" class="lazyload"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(loss_list)</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x22c32cef9e8&gt;]</code></pre><p><img alt="png" data-src="/2020/01/06/20200106-TensorFlow%E5%AE%9E%E7%8E%B0%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/output_41_1.png" class="lazyload"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(loss_list,<span class="string">'r+'</span>)</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x22c32d45ba8&gt;]</code></pre><p><img alt="png" data-src="/2020/01/06/20200106-TensorFlow%E5%AE%9E%E7%8E%B0%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/output_42_1.png" class="lazyload"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[x <span class="keyword">for</span> x <span class="keyword">in</span> loss_list <span class="keyword">if</span> x&gt;<span class="number">1</span>]</span><br></pre></td></tr></table></figure><pre><code>[1.4533501, 1.3507473, 1.7046989, 2.2887022, 1.7251762, 1.9852284, 1.1750387, 1.7792182, 1.1360258, 1.7623546, 1.132765, 1.7609351, 1.1324903, 1.7608157, 1.1324672, 1.7608054, 1.1324654, 1.7608048, 1.1324649, 1.7608048, 1.1324646, 1.7608044, 1.1324649]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 打印结果</span></span><br><span class="line">print(<span class="string">"w:"</span>, sess.run(w)) <span class="comment"># w的值应该在2附件</span></span><br><span class="line">print(<span class="string">"b:"</span>, sess.run(b)) <span class="comment"># b的值应该在1附近</span></span><br></pre></td></tr></table></figure><pre><code>w: 1.9070293b: 1.0205086</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可视化</span></span><br><span class="line">plt.scatter(x_data, y_data, label=<span class="string">"Original data"</span>)</span><br><span class="line">plt.plot(x_data,x_data * sess.run(w)+sess.run(b),label = <span class="string">"Fitted line"</span>, color = <span class="string">'r'</span>,linewidth = <span class="number">3</span>)</span><br><span class="line">plt.legend(loc = <span class="number">2</span>) <span class="comment"># 通过参数loc指定图例位置,左上角标签显示</span></span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.legend.Legend at 0x22c32da9c50&gt;</code></pre><p><img alt="png" data-src="/2020/01/06/20200106-TensorFlow%E5%AE%9E%E7%8E%B0%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/output_45_1.png" class="lazyload"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> xs,ys <span class="keyword">in</span> zip(x_data, y_data):</span><br><span class="line">    print(xs, ys)</span><br></pre></td></tr></table></figure><pre><code>-1.0 -0.8296403329862183-0.9797979797979798 -0.907915867983997-0.9595959595959596 -0.6940069139116888-0.9393939393939394 -0.44008198904613316-0.9191919191919192 -0.518056298082633-0.898989898989899 -0.8872131046936622-0.8787878787878788 0.06789250806751634-0.8585858585858586 -0.7121223166059172-0.8383838383838383 -1.0266771956105798-0.8181818181818181 -0.8591953886106469-0.797979797979798 -0.6488803761421159-0.7777777777777778 -0.7072455496370039-0.7575757575757576 -0.5902689976300266-0.7373737373737373 -0.3485610146594407-0.7171717171717171 -1.7479096133940975-0.696969696969697 -0.7054166950286986-0.6767676767676767 0.02660252968277821-0.6565656565656566 -0.0879307925836007-0.6363636363636364 -0.5449888988689496-0.6161616161616161 -0.4821245885002341-0.5959595959595959 0.26427918331828665-0.5757575757575757 -0.2506067288023764-0.5555555555555556 -0.3231932210702846-0.5353535353535352 0.6715786910122715-0.5151515151515151 -0.17825188097185915-0.4949494949494949 0.2837997365730506-0.4747474747474747 0.03223693168166275-0.4545454545454545 0.11122375083990527-0.43434343434343425 -0.24757709110216308-0.41414141414141414 -0.15907779562657415-0.3939393939393939 0.7153506547917942-0.3737373737373737 -0.20303085077192035-0.3535353535353535 0.4038733399023537-0.33333333333333326 -0.14444505243328032-0.31313131313131304 0.2775626397745727-0.2929292929292928 0.39925810781510473-0.2727272727272727 -0.19732590501344383-0.2525252525252525 0.9488948450886014-0.23232323232323226 0.46183376274541277-0.21212121212121204 1.0616526671192374-0.19191919191919182 0.24245017816545178-0.1717171717171716 1.0213106217668546-0.1515151515151515 1.6306657350096654-0.13131313131313127 0.8239865196438662-0.11111111111111105 0.5189503868361454-0.09090909090909083 1.0096642401086826-0.07070707070707061 0.9149167196744973-0.050505050505050386 0.8149904585811949-0.030303030303030276 0.8911912817877188-0.010101010101010055 0.74826766678925940.010101010101010166 1.18974905751868580.030303030303030498 0.90567351526606330.05050505050505061 0.75826284168208970.07070707070707072 1.46753969864337640.09090909090909105 1.11549177457064670.11111111111111116 2.28036360037980760.1313131313131315 1.16283831200039220.1515151515151516 1.01609514505545740.1717171717171717 1.12363541048898670.19191919191919204 1.53227316407232880.21212121212121215 1.1453041019262370.2323232323232325 0.95932599938001550.2525252525252526 2.1607354389680980.27272727272727293 1.0493966910905730.29292929292929304 2.19131689305766160.31313131313131315 1.6826852528906240.3333333333333335 1.24182748311133850.3535353535353536 2.3736228676983310.3737373737373739 1.6660933058664980.39393939393939403 1.38485977664746620.41414141414141437 1.85444665199489460.4343434343434345 2.3832651640036880.4545454545454546 2.18258823597854820.4747474747474749 2.27999286786918940.49494949494949503 2.69163351959694850.5151515151515154 2.116128624114660.5353535353535355 2.22103298487163150.5555555555555556 2.02071744491074150.5757575757575759 1.56963760307356330.595959595959596 2.134105328006630.6161616161616164 2.87911475452715050.6363636363636365 1.58030582148225430.6565656565656568 2.85070976699570530.6767676767676769 2.45815118309388270.696969696969697 2.02973165236894550.7171717171717173 2.46053123064597120.7373737373737375 3.1852763264068410.7575757575757578 2.28589823980159720.7777777777777779 2.87179300071438660.7979797979797982 3.0485651854539460.8181818181818183 2.27752603736069140.8383838383838385 2.92985242154697460.8585858585858588 2.93123377822040960.8787878787878789 2.56791479345059330.8989898989898992 3.07197416373106340.9191919191919193 2.69390616428374850.9393939393939394 2.64781590499802370.9595959595959598 2.4253001195389720.9797979797979799 3.11378791689627481.0 2.82832400301817</code></pre><h2 id="进行预测"><a href="#进行预测" class="headerlink" title="进行预测"></a>进行预测</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x_test = <span class="number">3.21</span></span><br><span class="line"></span><br><span class="line">predict = sess.run(pred, feed_dict = &#123;x:x_test&#125;)</span><br><span class="line">print(<span class="string">"预测值：%f"</span> %predict)</span><br><span class="line"></span><br><span class="line">target = <span class="number">2</span> * x_test +<span class="number">1.0</span></span><br><span class="line">print(<span class="string">"目标值：%f"</span> %target)</span><br></pre></td></tr></table></figure><pre><code>预测值：7.142073目标值：7.420000</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 等价于上面的predict</span></span><br><span class="line">x_test = <span class="number">3.21</span></span><br><span class="line">predict = sess.run(w) * x_test + sess.run(b)</span><br><span class="line">print(<span class="string">"预测值：%f"</span> %predict)</span><br></pre></td></tr></table></figure><pre><code>预测值：7.142073</code></pre>]]></content>
    
    <summary type="html">
    
      TensorFlow实现单变量线性回归
    
    </summary>
    
    
      <category term="TensorFlow" scheme="https://smallbenxiong.github.io/categories/TensorFlow/"/>
    
    
      <category term="TensorFlow" scheme="https://smallbenxiong.github.io/tags/TensorFlow/"/>
    
      <category term="深度学习" scheme="https://smallbenxiong.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="线性回归" scheme="https://smallbenxiong.github.io/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    
  </entry>
  
  <entry>
    <title>Sqoop | Sqoop报错解决</title>
    <link href="https://smallbenxiong.github.io/2019/12/20/20191220-Sqoop%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3/"/>
    <id>https://smallbenxiong.github.io/2019/12/20/20191220-Sqoop%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3/</id>
    <published>2019-12-19T16:00:00.000Z</published>
    <updated>2019-12-20T01:54:51.873Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="Sqoop-Sqoop报错解决"><a href="#Sqoop-Sqoop报错解决" class="headerlink" title="Sqoop | Sqoop报错解决"></a>Sqoop | Sqoop报错解决</h1><h2 id="Job-failed-as-tasks-failed"><a href="#Job-failed-as-tasks-failed" class="headerlink" title="Job failed as tasks failed."></a>Job failed as tasks failed.</h2><pre><code>19/12/20 06:43:56 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1576794672412_000119/12/20 06:43:58 INFO impl.YarnClientImpl: Submitted application application_1576794672412_000119/12/20 06:43:58 INFO mapreduce.Job: The url to track the job: http://bp01:8088/proxy/application_1576794672412_0001/19/12/20 06:43:58 INFO mapreduce.Job: Running job: job_1576794672412_000119/12/20 06:44:17 INFO mapreduce.Job: Job job_1576794672412_0001 running in uber mode : false19/12/20 06:44:17 INFO mapreduce.Job:  map 0% reduce 0%19/12/20 06:44:25 INFO mapreduce.Job:  map 100% reduce 0%19/12/20 06:44:27 INFO mapreduce.Job: Job job_1576794672412_0001 failed with state FAILED due to: Task failed   task_1576794672412_0001_m_000000Job failed as tasks failed. failedMaps:1 failedReduces:0</code></pre><p><strong>解决：<br>查看日志:/opt/hadoop/hadoop-2.7.6/logs/userlogs/application_1576794672412_0006/container_1576794672412_0006_01_000002</strong>   </p><pre><code>2019-12-20 07:12:27,425 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException:   com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column  &apos;gender&apos; at row 1Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long   for column &apos;gender&apos; at row 1</code></pre><p><strong>！！ Data too long for column  ‘gender’ at row 1</strong></p><p>参考：<a href="https://blog.csdn.net/sunjinjuan/article/details/88854091" target="_blank" rel="noopener">sqoop从hive导出到mysql报错：failed with state FAILED due to: Task failed</a></p><hr><h2 id="Hive导入MySQL的数据全部出现在同一列"><a href="#Hive导入MySQL的数据全部出现在同一列" class="headerlink" title="Hive导入MySQL的数据全部出现在同一列"></a>Hive导入MySQL的数据全部出现在同一列</h2><pre><code>Hive数据+------------------------+------------------------+--+| interim_gender.gender  | interim_gender.amount  |+------------------------+------------------------+--+| 0                      | 33232                  || 1                      | 33215                  || 2                      | 33553                  |+------------------------+------------------------+--+</code></pre><p>导入：sqoop export –connect jdbc:mysql://192.168.43.122:3306/mall –username root –password *** –table gender –input-fields-terminated-by ‘\001’ –export-dir ‘/user/hive/warehouse/mall.db/interim_gender’ -m 1;</p><pre><code>MySQL数据+----------+---------+--+|  gender  | amount  |+----------+---------+--+| 1    33215  | NULL    || 2    33553  | NULL    || 0    33232  | NULL    |+----------+---------+--+</code></pre><p><strong>解决：<br>查看Hive数据格式</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ hadoop fs -cat &#x2F;user&#x2F;hive&#x2F;warehouse&#x2F;mall.db&#x2F;interim_gender&#x2F;000000_0</span><br><span class="line">033232</span><br><span class="line">133215</span><br><span class="line">233553</span><br></pre></td></tr></table></figure><p><strong>数据由Tab键分割,改为：<code>--fields-terminated-by &#39;\t&#39;</code> 即可。</strong></p><h2 id="佛系更新……"><a href="#佛系更新……" class="headerlink" title="佛系更新……"></a>佛系更新……</h2>]]></content>
    
    <summary type="html">
    
      Sqoop遇到的问题
    
    </summary>
    
    
      <category term="Hadoop" scheme="https://smallbenxiong.github.io/categories/Hadoop/"/>
    
    
      <category term="Sqoop" scheme="https://smallbenxiong.github.io/tags/Sqoop/"/>
    
      <category term="Hadoop" scheme="https://smallbenxiong.github.io/tags/Hadoop/"/>
    
      <category term="BigData" scheme="https://smallbenxiong.github.io/tags/BigData/"/>
    
      <category term="大数据" scheme="https://smallbenxiong.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://smallbenxiong.github.io/2019/12/15/hello-world/"/>
    <id>https://smallbenxiong.github.io/2019/12/15/hello-world/</id>
    <published>2019-12-14T16:00:00.000Z</published>
    <updated>2020-01-07T05:20:09.161Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><ul><li><strong>这是我的个人博客，主要用于记录自己的学习笔记，未申请百度、谷歌等搜索功能，只能通过域名访问。😁😁😁</strong>   </li><li><strong>如果转载了您的文章，我会进行标注，主要是方便自己浏览和学习，如果您介意的话麻烦您留个言，我马上删除。🤞🙆‍♀️🙆‍♂️</strong>   </li><li><strong>如果您正好浏览到我的网页，那可真是太有缘了，留个言再走鸭鸭鸭。🙄🙄🙄</strong></li></ul><hr><h1 id="关于博客"><a href="#关于博客" class="headerlink" title="关于博客"></a>关于博客</h1><p>本<a href="https://smallbenxiong.github.io/">博客</a>是搭建在<a href="https://github.com/smallbenxiong" target="_blank" rel="noopener">GitHub</a>上使用的静态网页，网页使用了<a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>，这让我的博客搭建变得非常快捷，非常美观，而且完美适配手机端浏览。使用的主题为<a href="https://demo.jerryc.me/" target="_blank" rel="noopener">Butterfly</a>。<br>同时这也是一篇介绍功能使用和测试功能的文章，文章持续更新！</p><h1 id="博客使用方法"><a href="#博客使用方法" class="headerlink" title="博客使用方法"></a>博客使用方法</h1><h2 id="格式设置"><a href="#格式设置" class="headerlink" title="格式设置"></a>格式设置</h2><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title:</span><br><span class="line">date:</span><br><span class="line">tags:</span><br><span class="line">categories:</span><br><span class="line">keywords:</span><br><span class="line">description:</span><br><span class="line">top_img: （除非特定需要，可以不写）</span><br><span class="line">comments  是否显示评论（除非设置false,可以不写）</span><br><span class="line">cover:  缩略图</span><br><span class="line">toc:  是否显示toc （除非特定文章设置，可以不写）</span><br><span class="line">toc_number: 是否显示toc数字 （除非特定文章设置，可以不写）</span><br><span class="line">copyright: 是否显示版权 （除非特定文章设置，可以不写）</span><br><span class="line">default_cover:</span><br><span class="line">top: </span><br><span class="line">---</span><br></pre></td></tr></table></figure><h3 id="不显示版权"><a href="#不显示版权" class="headerlink" title="不显示版权"></a>不显示版权</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">如果有文章（例如：转载文章）不需要显示版权，可以在文章Front-matter单独设置</span><br><span class="line">$ copyright: <span class="literal">false</span></span><br></pre></td></tr></table></figure><h3 id="文章封面"><a href="#文章封面" class="headerlink" title="文章封面"></a>文章封面</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">文章的markdown文档上,在Front-matter添加cover，并填上要显示的图片地址。</span><br><span class="line">当配置多张图片时，会随机选择一张作为cover。此时写法应为：</span><br><span class="line">default_cover:</span><br><span class="line">  - https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png</span><br><span class="line">  - https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg2.png</span><br><span class="line">  - https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg3.png</span><br></pre></td></tr></table></figure><h3 id="文章置顶"><a href="#文章置顶" class="headerlink" title="文章置顶"></a>文章置顶</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">在文章的front-matter区域里添加top: True属性来把这篇文章置顶。</span><br><span class="line">$ top: True</span><br></pre></td></tr></table></figure><h2 id="搜索系统"><a href="#搜索系统" class="headerlink" title="搜索系统"></a>搜索系统</h2><p>搜索系统使用<a href="https://www.algolia.com/" target="_blank" rel="noopener">Algolia</a>，配置参考<a href="https://github.com/oncletom/hexo-algolia" target="_blank" rel="noopener">hexo-algolia</a>。</p><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">export</span>(windows为<span class="built_in">set</span>) HEXO_ALGOLIA_INDEXING_KEY=&#123;your key&#125;</span><br></pre></td></tr></table></figure><h3 id="更新Algolia库"><a href="#更新Algolia库" class="headerlink" title="更新Algolia库"></a>更新Algolia库</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo algolia</span><br></pre></td></tr></table></figure><h2 id="音乐设置"><a href="#音乐设置" class="headerlink" title="音乐设置"></a>音乐设置</h2><p>使用<a href="https://github.com/MoePlayer/hexo-tag-aplayer" target="_blank" rel="noopener">hexo-tag-aplayer</a>的MeingJS插件，参考<a href="https://wiki.hushhw.cn/posts/a84d1ef1.html" target="_blank" rel="noopener">aplayer播放器配置</a> 。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1. 单首设置</span><br><span class="line">$ &#123;% meting <span class="string">"3986040"</span> <span class="string">"netease"</span> <span class="string">"song"</span> <span class="string">"theme:#555"</span> <span class="string">"mutex:true"</span> <span class="string">"listmaxheight:340px"</span> <span class="string">"preload:auto"</span> %&#125;</span><br><span class="line">2. 列表设置</span><br><span class="line">$ &#123;% meting <span class="string">"627070825"</span> <span class="string">"netease"</span> <span class="string">"playlist"</span> <span class="string">"theme:#555"</span> <span class="string">"mutex:true"</span> <span class="string">"listmaxheight:340px"</span> <span class="string">"preload:auto"</span> %&#125;</span><br></pre></td></tr></table></figure><h3 id="音乐参数"><a href="#音乐参数" class="headerlink" title="音乐参数"></a>音乐参数</h3><table><thead><tr><th align="center">选项</th><th align="center">默认值</th><th align="center">描述</th></tr></thead><tbody><tr><td align="center">id</td><td align="center">必须值</td><td align="center">歌曲 id / 播放列表 id / 相册 id / 搜索关键字</td></tr><tr><td align="center">server</td><td align="center">必须值</td><td align="center">音乐平台: netease, tencent, kugou, xiami, baidu</td></tr><tr><td align="center">type</td><td align="center">必须值</td><td align="center">song, playlist, album, search, artist</td></tr><tr><td align="center">fixed</td><td align="center">false</td><td align="center">开启固定模式</td></tr><tr><td align="center">mini</td><td align="center">false</td><td align="center">开启迷你模式</td></tr><tr><td align="center">loop</td><td align="center">all</td><td align="center">列表循环模式：all, one,none</td></tr><tr><td align="center">order</td><td align="center">list</td><td align="center">列表播放模式： list, random</td></tr><tr><td align="center">volume</td><td align="center">0.7</td><td align="center">播放器音量</td></tr><tr><td align="center">lrctype</td><td align="center">0</td><td align="center">歌词格式类型</td></tr><tr><td align="center">listfolded</td><td align="center">false</td><td align="center">指定音乐播放列表是否折叠</td></tr><tr><td align="center">storagename</td><td align="center">metingjs</td><td align="center">LocalStorage 中存储播放器设定的键名</td></tr><tr><td align="center">autoplay</td><td align="center">true</td><td align="center">自动播放，移动端浏览器暂时不支持此功能</td></tr><tr><td align="center">mutex</td><td align="center">true</td><td align="center">该选项开启时，如果同页面有其他 aplayer 播放，该播放器会暂停</td></tr><tr><td align="center">listmaxheight</td><td align="center">340px</td><td align="center">播放列表的最大长度</td></tr><tr><td align="center">preload</td><td align="center">auto</td><td align="center">音乐文件预载入模式，可选项： none, metadata, auto</td></tr><tr><td align="center">theme</td><td align="center">#ad7a86</td><td align="center">播放器风格色彩设置</td></tr></tbody></table><h2 id="文件上传"><a href="#文件上传" class="headerlink" title="文件上传"></a>文件上传</h2><h3 id="生成静态文件"><a href="#生成静态文件" class="headerlink" title="生成静态文件"></a>生成静态文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br></pre></td></tr></table></figure><h3 id="部署至github"><a href="#部署至github" class="headerlink" title="部署至github"></a>部署至github</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo d</span><br></pre></td></tr></table></figure><h1 id="赞助"><a href="#赞助" class="headerlink" title="赞助"></a>赞助</h1><table><thead><tr><th align="center">用户名</th><th align="center">金额/元</th><th align="center">留言</th></tr></thead><tbody><tr><td align="center">Ben</td><td align="center">99</td><td align="center">Thanks！</td></tr><tr><td align="center">…</td><td align="center">…</td><td align="center">…</td></tr></tbody></table><p>More info: <a href="https://smallbenxiong.github.io/">Ben Blog</a></p>]]></content>
    
    <summary type="html">
    
      博客的使用方法
    
    </summary>
    
    
      <category term="Blog" scheme="https://smallbenxiong.github.io/categories/Blog/"/>
    
    
      <category term="Blog" scheme="https://smallbenxiong.github.io/tags/Blog/"/>
    
  </entry>
  
</feed>
